\BOOKMARK [1][-]{section.1}{Multistep Q-Learning}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{TD-Learning Bias \(2 points\)}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Tabular Learning \(6 points total\)}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Variance of Q Estimate \(2 points\)}{section.1}% 4
\BOOKMARK [2][-]{subsection.1.4}{Function Approximation \(2 points\)}{section.1}% 5
\BOOKMARK [2][-]{subsection.1.5}{Multistep Importance Sampling \(5 points\)}{section.1}% 6
\BOOKMARK [1][-]{section.2}{Deep Q-Learning}{}% 7
\BOOKMARK [2][-]{subsection.2.1}{Introduction}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.2}{File overview}{section.2}% 9
\BOOKMARK [2][-]{subsection.2.3}{Implementation}{section.2}% 10
\BOOKMARK [2][-]{subsection.2.4}{Basic Q-Learning}{section.2}% 11
\BOOKMARK [2][-]{subsection.2.5}{Double Q-Learning}{section.2}% 12
\BOOKMARK [2][-]{subsection.2.6}{Experimenting with Hyperparameters}{section.2}% 13
\BOOKMARK [1][-]{section.3}{Continuous Actions with Actor-Critic}{}% 14
\BOOKMARK [2][-]{subsection.3.1}{Implementation}{section.3}% 15
\BOOKMARK [3][-]{subsubsection.3.1.1}{Bootstrapping}{subsection.3.1}% 16
\BOOKMARK [3][-]{subsubsection.3.1.2}{Entropy Bonus and Soft Actor-Critic}{subsection.3.1}% 17
\BOOKMARK [3][-]{subsubsection.3.1.3}{Actor with REINFORCE}{subsection.3.1}% 18
\BOOKMARK [3][-]{subsubsection.3.1.4}{Actor with REPARAMETRIZE}{subsection.3.1}% 19
\BOOKMARK [3][-]{subsubsection.3.1.5}{Stabilizing Target Values}{subsection.3.1}% 20
\BOOKMARK [1][-]{section.4}{Submitting the code and experiment runs}{}% 21
